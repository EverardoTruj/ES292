---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#Chapter 2


#Grid aporximation

p_grid<-seq(from=0, to=1, length.out=20)
prior<-rep(1,20)
likelihood<-dbinom(7,10,prob = p_grid)
Posterior<-(likelihood*prior)/sum(likelihood*prior)
plot(p_grid, Posterior, type="b",
     xlab="Probability of water", ylab="Posterior probability")

```

```{r}
#Chapter 3
library(rethinking)
p_grid<-seq(from=0,to=1, length.out=1000)
prior<-rep(1,1000)
likelihood<-dbinom(7,10,p_grid)
posterior<-(likelihood*prior)/sum(likelihood*prior)
posterior

#sampling
samples <- sample(p_grid, prob=posterior, size=1e4, replace=TRUE)
plot(samples)
dens(samples)

#add up posterior probability where p<0.5. SO abut 11% of the posterior probability is below 0.5
sum(posterior[p_grid<0.5])

#Posterior between two values
sum( samples > 0.5 & samples < 0.75 ) / 1e4

#Lower 80% posterior probability exists below a parameter value of about 0.78
quantile(samples, 0.8)

#Middle 80% posterior probability lies between the 10% and 90% quantiles
quantile(samples,c(0.1,0.9))

#highest posterior density interval (HPDI). s the narrowest interval containing the specified probability mass. 
HPDI( samples , prob=0.5 )

#Dummy data
dbinom( 0:2 , size=2 , prob=0.7 )

#The “r” in rbinom stands for “random.”
rbinom( 10 , size=2 , prob=0.7 )

dummy1<-rbinom( 100000 , size=2 , prob=0.7 )
table(dummy1)/1e5

dummy2<-rbinom( 100000 , size=2 , prob=0.7 )
table(dummy2)/1e5

```
```{r}
#chapter 4. Linear models

```

```{r}
#Chapter 5: Multivariate linear models

# load data
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# standardize predictor
d$MedianAgeMarriage.s <- (d$MedianAgeMarriage-mean(d$MedianAgeMarriage))/
sd(d$MedianAgeMarriage)
# fit model
m5.1 <- map(
alist(
Divorce ~ dnorm( mu , sigma ) ,
mu <- a + bA * MedianAgeMarriage.s ,
a ~ dnorm( 10 , 10 ) ,
bA ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) , data = d )

m5.1

precis(m5.1)


# compute percentile interval of mean
MAM.seq <- seq( from=-3 , to=3.5 , length.out=30 )
mu <- link( m5.1 , data=data.frame(MedianAgeMarriage.s=MAM.seq) )
mu.PI <- apply( mu , 2 , PI )
# plot it all
plot( Divorce ~ MedianAgeMarriage.s , data=d , col=rangi2 )
abline( m5.1 )
shade( mu.PI , MAM.seq )

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.
```{r}
d$Marriage.s <- (d$Marriage - mean(d$Marriage))/sd(d$Marriage)
m5.2 <- map(
alist(
Divorce ~ dnorm( mu , sigma ) ,
mu <- a + bR * Marriage.s ,
a ~ dnorm( 10 , 10 ) ,
bR ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) , data = d )

m5.2

precis(m5.2)
```
```{r}
#First example of multivariate model
m5.3 <- map(
alist(
Divorce ~ dnorm( mu , sigma ) ,
mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s ,
a ~ dnorm( 10 , 10 ) ,
bR ~ dnorm( 0 , 1 ) ,
bA ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data = d )
precis( m5.3 )


#posterior distribution estimates
plot( precis(m5.3) )
```
```{r}
#5E2. Write down a multiple regression to evaluate the claim: Animal diversity is linearly related tolatitude, but only after controlling for plant diversity. You just need to write down the model definition
library(rethinking)
#AD=(a+BiPDi)+BiLi

#5E3. Write down a multiple regression to evaluate the claim: Neither amount of funding nor siz of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree. Write down the model definition and indicate which side of zero each slope parameter should be on.
#T=a+B(F+S)


#5M1. Invent your own example of a spurious correlation. An outcome variable should be correlated with both predictor variables. But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish (or at least be greatly reduced).

#Lets supose the case of the births of female in a crocodile nest.the gender in the crocodiles is determinated by the temperature at the eggs are incubated. The higher the temperature, the greater the percentage of females there will be. So we can consider the temperature as our real predictor, with a positive slope. At the other hand, There are certain species of grasses that crocodiles usually choose to build their nests, which usually grow in warm climates.



#5M2. Invent your own example of a masked relationship. An outcome variable should be correlated with both predictor variables, but in opposite directions. And the two predictor variables should be correlated with one another

#Suppose an amphibian population is positively determined by the humidity of its environment, but humidity also positively affects its primary predator populations. The predator population has a negative effect on the amphibian population and the effect of humidity is positive
```


```{r}
#Hard. All three exercises below use the same data, data(foxes) (part of rethinking).81 The urban fox (Vulpes vulpes) is a successful exploiter of human habitat. Since urban foxes move in packs and defend territories, data on habitat quality and population density is also included. The data frame has five columns: 
#(1) group: Number of the social group the individual fox belongs to
#(2) avgfood: The average amount of food available in the territory
#(3) groupsize: The number of foxes in the social group
#(4) area: Size of the territory
#(5) weight: Body weight of the individual fox

data(foxes)
D<-foxes
D
#5H1. Fit two bivariate Gaussian regressions, using map: (1) body weight as a linear function of territory size (area), and (2) body weight as a linear function of groupsize. Plot the results of these regressions, displaying the MAP regression line and the 95% interval of the mean. Is either variable important for predicting fox body weight?

# standardize predictor
D$area <- (D$area-mean(D$area))/sd(D$area)
D$groupsize <- (D$groupsize-mean(D$groupsize))/sd(D$groupsize)


# fit models
H1.1 <- map(
alist(
weight ~ dnorm( mu , sigma ) ,
mu <- a + bA * D$area ,
a ~ dnorm( 8 , 3) ,
bA ~ dnorm( 2 , 10 ) ,
sigma ~ dunif( 0 , 5 )
) , data = D )



H1.2 <- map(
alist(
weight ~ dnorm( mu , sigma ) ,
mu <- a + bR * D$groupsize ,
a ~ dnorm( 4 , 3 ) ,
bR ~ dnorm( 2 , 10 ) ,
sigma ~ dunif( 0 , 5 )
) , data = D )

precis( H1.1 , TRUE )
precis( H1.2 , TRUE )

postH1.1 <- extract.samples(H1.1, n=30 )
postH1.2 <- extract.samples(H1.2, n=30 )

# display raw data and sample size
N<-30
plot(  D$area , D$weight,
xlim=range(D$area) , ylim=range(D$weight) ,
col=rangi2 , xlab="Area" , ylab="Weight" )
mtext(concat("N = ",N))
# plot the lines, with transparency
for ( i in 1:30 )
abline( a=post$a[i] , b=post$b[i] , col=col.alpha("black",0.9)) 

N<-30
plot( D$groupsize, D$weight , 
xlim=range(D$groupsize) , ylim=range(D$weight) ,
col=rangi2 , xlab="Group size" , ylab="weight" )
mtext(concat("N = ",N))
# plot the lines, with transparency
for ( i in 1:30 )
abline( a=post$a[i] , b=post$b[i] , col=col.alpha("black",0.9))

```


```{r}
#5H2. Now fit a multiple linear regression with weight as the outcome and both area and groupsize as predictor variables. Plot the predictions of the model for each predictor, holding the other predictor constant at its mean. What does this model say about the importance of each variable? Why do you get different results than you got in the exercise just above?

H2.2 <- map(
alist(
weight ~ dnorm( mu , sigma ) ,
mu <- a + bA * D$area +bR*D$groupsize,
a ~ dnorm( 4 , 1) ,
bA ~ dnorm( 2 , 10 ),
bR ~ dnorm( 2 , 10 ),
sigma ~ dunif( 0 , 5 )
) , data = D )

precis(H2.2)

postH2.1 <- extract.samples(H2.2, n=30 )

data(foxes)
# prepare new counterfactual data
W.avg <- mean(  D$area )
R.seq <- seq( from=-20 , to=20 , length.out=116 )

pred.data <- data.frame(R.seq,W.avg)

# compute counterfactual mean weight (mu)
mu <- link( H2.2 , data=pred.data )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI )

# simulate counterfactual weight outcomes
R.sim <- sim(H2.2 , data=pred.data , n=1e4)
R.PI <- apply( R.sim , 2 , PI )

# display predictions, hiding raw data with type="n"
plot( weight ~ D$area , data=D , type="n" )
mtext( "MedianAgeMarriage.s = 0" )
lines( R.seq , mu.mean )
shade( mu.PI , R.seq )
shade( R.PI , R.seq )



# prepare new counterfactual data
W.avg2 <- mean(  D$groupsize )
R.seq2 <- seq( from=-20 , to=20 , length.out=116 )

pred.data2 <- data.frame(R.seq2,W.avg2)

# compute counterfactual mean weight (mu)
mu2 <- link( H2.2 , data=pred.data2 )
mu.mean2 <- apply( mu2 , 2 , mean )
mu.PI2 <- apply( mu2 , 2 , PI )

# simulate counterfactual weight outcomes
R.sim2 <- sim(H2.2 , data=pred.data2 , n=1e4)
R.PI2 <- apply( R.sim2 , 2 , PI )

# display predictions, hiding raw data with type="n"
plot( weight ~ D$groupsize , data=D , type="n" )
mtext( "MedianAgeMarriage.s = 0" )
lines( R.seq2 , mu.mean2 )
shade( mu.PI2 , R.seq2 )
shade( R.PI2 , R.seq2 )
```


```{r}
#5H3. Finally, consider the avgfood variable. Fit two more multiple regressions: (1) body weight as an additive function of avgfood and groupsize, and (2) body weight as an additive function of all three variables, avgfood and groupsize and area. Compare the results of these models to the previous models you’ve fit, in the first two exercises. (a) Is avgfood or area a better predictor of body weight? If you had to choose one or the other to include in a model, which would it be? Support your assessment with any tables or plots you choose. (b) When both avgfood or area are in the same model, their effects are reduced (closer to zero) and their standard errors are larger than when they are included in separate models. Can you explain this result?

H3.1 <- map(
alist(
weight ~ dnorm( mu , sigma ) ,
mu <- a +bR*D$groupsize+bZ*D$avgfood,
a ~ dnorm( 4 , 10) ,
bR ~ dnorm( 4 , 10 ),
bZ ~ dnorm( 4 , 10 ),
sigma ~ dunif( 0 , 10 )
) , data = D )

precis(H3.1)

H3.2 <- map(
alist(
weight ~ dnorm( mu , sigma ) ,
mu <- a + bA * D$area +bR*D$groupsize+bZ*D$avgfood,
a ~ dnorm( 4 , 1) ,
bA ~ dnorm( 0 , 1 ),
bR ~ dnorm( 0 , 1 ),
bZ ~ dnorm( 0 , 1 ),
sigma ~ dunif( 0 , 10 )
) , data = D )


# prepare new counterfactual data
W.avg3.1 <- mean(  D$avgfood )
R.seq3.1 <- seq( from=-20 , to=20 , length.out=116 )

pred.data3.1 <- data.frame(R.seq3.1,W.avg3.1)

# compute counterfactual mean weight (mu)
mu3.1 <- link( H3.1 , data=pred.data3.1 )
mu.mean3.1 <- apply( mu3.1 , 2 , mean )
mu.PI3.1 <- apply( mu3.1 , 2 , PI )

# simulate counterfactual weight outcomes
R.sim3.1 <- sim(H3.1 , data=pred.data3.1 , n=1e4)
R.PI3.1 <- apply( R.sim3.1 , 2 , PI )

# display predictions, hiding raw data with type="n"
plot( weight ~ D$avgfood , data=D , type="n" )
mtext( "Median group size" )
lines( R.seq3.1 , mu.mean3.1 )
shade( mu.PI3.1 , R.seq3.1 )
shade( R.PI3.1 , R.seq3.1 )



```
```{r}
#Chapter 7

library(rethinking)
data(rugged)
d7 <- rugged

d7
# make log version of outcome
d7$log_gdp<-log(d7$rgdppc_2000)

# extract countries with GDP data
dd<-d7[complete.cases(d7$rgdppc_2000),]

# split countries into Africa and not-Africa
d.A1<-dd[dd$cont_africa==1,]#Africa
d.A0<-dd[dd$cont_africa==0,]#Africa

#Fitting the modeles:
#African nations

m7.1<-map(
  alist(
  log_gdp ~ dnorm(mu,sigma),
  mu <-a+bR*rugged,
  a ~ dnorm(8,100),
  bR ~  dnorm(0,1),
  sigma ~ dunif(0,10)
  ),
data= d.A1)

m7.1
#Non-African nations
m7.2<-map(
  alist(
  log_gdp ~ dnorm(mu,sigma),
  mu <-a+bR*rugged,
  a ~ dnorm(8,100),
  bR ~  dnorm(0,1),
  sigma ~ dunif(0,10)
  ),
data= d.A0)

precis(m7.1)
precis(m7.2)


#plotting
plot(log_gdp ~ rugged, d7 )
abline(a=coef(m7.1) ["a"], b=coef(m7.1) ["bR"] )

# define sequence of weights to compute predictions for these values will be on the horizontal axis
rugged.seq <- seq( from=0 , to=7 , by=1 )

# use link to compute mu for each sample from posterior and for each rugged index in rugged.seq
mu <- link( m7.1 , data=data.frame(rugged=rugged.seq) )
sim.log_gdp<- sim( m7.1 , data=list(rugged=rugged.seq) )
mu

#For affrican nations
# summarize the distribution of mu
mu.mean <- apply( mu , 2 , mean )
mu.HPDI <- apply( mu , 2 , HPDI , prob=0.89 )
 
# plot raw data fading out points to make line and interval more visible
plot( log_gdp ~ rugged , data=d7 , col=col.alpha(rangi2,0.5) )
# plot the MAP line, aka the mean mu for each weight
lines( rugged.seq , mu.mean )
# plot a shaded region for 89% HPDI
shade( mu.HPDI , rugged.seq ) 

#Another example
sim.log_gdp <- sim( m7.1 , data=list(rugged=rugged.seq) )
log_gdp.PI <- apply( sim.log_gdp , 2 , PI , prob=0.89 )
# plot raw data
plot( log_gdp ~ rugged , d7 , col=col.alpha(rangi2,0.5) )
# draw MAP line
lines( rugged.seq , mu.mean )
# draw HPDI region for line
shade( mu.HPDI , rugged.seq )
# draw PI region for simulated heights
shade( log_gdp.PI , rugged.seq )

#For non-African-Nations

mu <- link( m7.2 , data=data.frame(rugged=rugged.seq) )
str(mu)
sim.log_gdp<- sim( m7.2 , data=list(rugged=rugged.seq) )

# summarize the distribution of mu
mu.mean2 <- apply( mu , 2 , mean )
mu.HPDI2 <- apply( mu , 2 , HPDI , prob=0.89 )
 
# plot raw data fading out points to make line and interval more visible
plot( log_gdp ~ rugged , data=d7 , col=col.alpha(rangi2,0.5) )
# plot the MAP line, aka the mean mu for each weight
lines( rugged.seq , mu.mean2 )
# plot a shaded region for 89% HPDI
shade( mu.HPDI2 , rugged.seq ) 


sim.log_gdp2 <- sim( m7.2 , data=list(rugged=rugged.seq) )
log_gdp.PI2 <- apply( sim.log_gdp2 , 2 , PI , prob=0.89 )
# plot raw data
plot( log_gdp ~ rugged , d7 , col=col.alpha(rangi2,0.5) )
# draw MAP line
lines( rugged.seq , mu.mean2 )
# draw HPDI region for line
shade( mu.HPDI2 , rugged.seq )
# draw PI region for simulated heights
shade( log_gdp.PI2 , rugged.seq )
```
```{r}
#Adding dummy variable

#Normal
m7.3 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged ,
a ~ dnorm( 8 , 100 ) ,
bR ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data=dd )

#Whit dummy variable
m7.4 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa ,
a ~ dnorm( 8 , 100 ) ,
bR ~ dnorm( 0 , 1 ) ,
bA ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data=dd )

rugged.seq <- seq(from=-1,to=8,by=0.25)
# compute mu over samples, fixing cont_africa=0
mu.NotAfrica <- link( m7.4 , data=data.frame(cont_africa=0,rugged=rugged.seq) )
# compute mu over samples, fixing cont_africa=1
mu.Africa <- link( m7.4 , data=data.frame(cont_africa=1,rugged=rugged.seq) )
# summarize to means and intervals
mu.NotAfrica.mean <- apply( mu.NotAfrica , 2 , mean )
mu.NotAfrica.PI <- apply( mu.NotAfrica , 2 , PI , prob=0.97 )
mu.Africa.mean <- apply( mu.Africa , 2 , mean )
mu.Africa.PI <- apply( mu.Africa , 2 , PI , prob=0.97 )


```

```{r}
#Adding linear interaction
m7.5 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + gamma*rugged + bA*cont_africa ,
gamma <- bR + bAR*cont_africa ,
a ~ dnorm( 8 , 100 ) ,
bA ~ dnorm( 0 , 1 ) ,
bR ~ dnorm( 0 , 1 ) ,
bAR ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data=dd )

m7.5
precis(m7.5)
#The gamma definition gets evaluated, and then those values are used to evaluate the definition of mu, and finally mu gets used to compute the likelihood.

help("apply")
dd$rugged
#Plotting the interactions
rugged.seq <- seq(from=0,to=7,by=1)
mu.Africa <- link( m7.5 , data.frame(cont_africa=1,rugged=rugged.seq) )
mu.Africa
mu.Africa.mean <- apply( mu.Africa , 2 , mean )
mu.Africa.PI <- apply( mu.Africa , 2 , PI , prob=0.97 )
mu.NotAfrica <- link( m7.5 , data=data.frame(cont_africa=0,rugged=rugged.seq) )
mu.NotAfrica.mean <- apply( mu.NotAfrica , 2 , mean )
mu.NotAfrica.PI <- apply( mu.NotAfrica , 2 , PI , prob=0.97 )

```

```{r}
Easy.
#6E1. State the three motivating criteria that define information entropy. Try to express each in your own words.
The measure of uncertainty should be continuous.
The measure of uncertainty should increase as the number of possible events increases. 
The measure of uncertainty should be additive

#6E2. Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?
 
 p <- c( 0.3 , 0.7 )
-sum( p*log(p) )=0.61
 
we add another kind of event to the distribution—forecasting into winter, so also predicting snow—entropy tends to increase, 

#6E3. Suppose a four-sided die is loaded such that, when tossed onto a table, it shows “1” 20%, “2” 25%, ”3” 25%, and ”4” 30% of the time. What is the entropy of this die?

 p <- c( 0.2, 0.25, 0.23, 0.3 )
-sum( p*log(p) ) 
#Entropy is 1.367878

#6E4. Suppose another four-sided die is loaded such that it never shows “4”. The other three sides show equally often. What is the entropy of this die?

p <- c( 0.2, 0.25, 0.23)
-sum( p*log(p) )
#Entropy is 1.00648

#Medium.206 6. OVERFITTING, REGULARIZATION, AND INFORMATION CRITERIA
#6M1. Write down and compare the definitions of AIC, DIC, and WAIC. Which of these criteria is most general? Which assumptions are required to transform a more general criterion into a less general one?

AIC<-estimate of the average out-of-sample deviance 
AIC = Dtrain + 2p
AIC is just the oldest and most restrictive

DIC(Deviance information criteria). accommodates informative priors, but still assumes that the posterior is multivariate Gaussian and that N ≫ k.
DIC is essentially a version of AIC that is aware of informative priors

WAIC (Widely Applicable Information Criterion) dont make assuumption about the shape of the posterior


#6M2. Explain the difference between model selection and model averaging. What information is lost under model selection? What information is lost under model averaging?

model selection, usually means choosing the model with the lowest AIC/DIC/WAIC value and then discarding the others. 

Model averaging means using DIC/WAIC to construct a posterior predictive distribution that exploits what we know about relative accuracy of the models. What model averaging does not mean is averaging parameter estimates, because parameters in different models have different meanings and should not be averaged, unless you are sure you are in a special case in which it is safe to do so. So it is better to think of model averaging as prediction averaging
  
#6M3. When comparing models with an information criterion, why must all models be fit to exactly the same observations? What would happen to the information criterion values, if the models were fit to different numbers of observations? Perform some experiments, if you are not sure.

If one model uses a predictor that has missing values, while another does not,
then each model will be fit to a different number of cases. The model fit to fewer observations will almost always have a better deviance and AIC/DIC/WAIC value, because it has been asked to predict less.

#6M4. What happens to the effective number of parameters, as measured by DIC or WAIC, as a prior becomes more concentrated? Why? Perform some experiments, if you are not sure.


#6M5. Provide an informal explanation of why informative priors reduce overfitting.

#6M6. Provide an information explanation of why overly informative priors result in underfitting.
```


```{r}

library(rethinking)
## R code 7.1
sppnames <- c( "afarensis","africanus","habilis","boisei",
    "rudolfensis","ergaster","sapiens")
brainvolcc <- c( 438 , 452 , 612, 521, 752, 871, 1350 )
masskg <- c( 37.0 , 35.5 , 34.5 , 41.5 , 55.5 , 61.0 , 53.5 )
d <- data.frame( species=sppnames , brain=brainvolcc , mass=masskg )

## R code 7.2
d$mass_std <- (d$mass - mean(d$mass))/sd(d$mass)
d$brain_std <- d$brain / max(d$brain)

## R code 7.3
m7.1 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b*mass_std,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d )

## R code 7.4
m7.1_OLS <- lm( brain_std ~ mass_std , data=d )
post <- extract.samples( m7.1_OLS )

## R code 7.5
set.seed(12)
s <- sim( m7.1 )
r <- apply(s,2,mean) - d$brain_std
resid_var <- var2(r)
outcome_var <- var2( d$brain_std )
1 - resid_var/outcome_var

## R code 7.6
R2_is_bad <- function( quap_fit ) {
    s <- sim( quap_fit , refresh=0 )
    r <- apply(s,2,mean) - d$brain_std
    1 - var2(r)/var2(d$brain_std)
}

## R code 7.7
m7.2 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,2)) )

## R code 7.8
m7.3 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,3)) )

m7.4 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,4)) )

m7.5 <- quap(
    alist(
        brain_std ~ dnorm( mu , exp(log_sigma) ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4 +
                  b[5]*mass_std^5,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 ),
        log_sigma ~ dnorm( 0 , 1 )
    ), data=d , start=list(b=rep(0,5)) )

## R code 7.9
m7.6 <- quap(
    alist(
        brain_std ~ dnorm( mu , 0.001 ),
        mu <- a + b[1]*mass_std + b[2]*mass_std^2 +
                  b[3]*mass_std^3 + b[4]*mass_std^4 +
                  b[5]*mass_std^5 + b[6]*mass_std^6,
        a ~ dnorm( 0.5 , 1 ),
        b ~ dnorm( 0 , 10 )
    ), data=d , start=list(b=rep(0,6)) )

## R code 7.10
post <- extract.samples(m7.1)
mass_seq <- seq( from=min(d$mass_std) , to=max(d$mass_std) , length.out=100 )
l <- link( m7.1 , data=list( mass_std=mass_seq ) )
mu <- apply( l , 2 , mean )
ci <- apply( l , 2 , PI )
plot( brain_std ~ mass_std , data=d )
lines( mass_seq , mu )
shade( ci , mass_seq )



## R code 7.12
p <- c( 0.3 , 0.7 )
-sum( p*log(p) )

## R code 7.13
set.seed(1)
lppd( m7.1 , n=1e4 )

## R code 7.14
set.seed(1)
logprob <- sim( m7.1 , ll=TRUE , n=1e4 )
n <- ncol(logprob)
ns <- nrow(logprob)
f <- function( i ) log_sum_exp( logprob[,i] ) - log(ns)
( lppd <- sapply( 1:n , f ) )

## R code 7.15
set.seed(1)
sapply( list(m7.1,m7.2,m7.3,m7.4,m7.5,m7.6) , function(m) sum(lppd(m)) )

## R code 7.16
N <- 20
kseq <- 1:5
dev <- sapply( kseq , function(k) {
        print(k);
        r <- replicate( 1e4 , sim_train_test( N=N, k=k ) );
        c( mean(r[1,]) , mean(r[2,]) , sd(r[1,]) , sd(r[2,]) )
    } )

## R code 7.17
        r <- mcreplicate( 1e4 , sim_train_test( N=N, k=k ) , mc.cores=4 )

## R code 7.18
plot( 1:5 , dev[1,] , ylim=c( min(dev[1:2,])-5 , max(dev[1:2,])+10 ) ,
    xlim=c(1,5.1) , xlab="number of parameters" , ylab="deviance" ,
    pch=16 , col=rangi2 )
mtext( concat( "N = ",N ) )
points( (1:5)+0.1 , dev[2,] )
for ( i in kseq ) {
    pts_in <- dev[1,i] + c(-1,+1)*dev[3,i]
    pts_out <- dev[2,i] + c(-1,+1)*dev[4,i]
    lines( c(i,i) , pts_in , col=rangi2 )
    lines( c(i,i)+0.1 , pts_out )
}

## R code 7.19
data(cars)
m <- quap(
    alist(
        dist ~ dnorm(mu,sigma),
        mu <- a + b*speed,
        a ~ dnorm(0,100),
        b ~ dnorm(0,10),
        sigma ~ dexp(1)
    ) , data=cars )
set.seed(94)
post <- extract.samples(m,n=1000)

## R code 7.20
n_samples <- 1000
logprob <- sapply( 1:n_samples ,
    function(s) {
        mu <- post$a[s] + post$b[s]*cars$speed
        dnorm( cars$dist , mu , post$sigma[s] , log=TRUE )
    } )

## R code 7.21
n_cases <- nrow(cars)
lppd <- sapply( 1:n_cases , function(i) log_sum_exp(logprob[i,]) - log(n_samples) )

## R code 7.22
pWAIC <- sapply( 1:n_cases , function(i) var(logprob[i,]) )

## R code 7.23
-2*( sum(lppd) - sum(pWAIC) )

## R code 7.24
waic_vec <- -2*( lppd - pWAIC )
sqrt( n_cases*var(waic_vec) )

## R code 7.25
set.seed(11)
WAIC( m6.7 )

## R code 7.26
set.seed(77)
compare( m6.6 , m6.7 , m6.8 , func=WAIC )

## R code 7.27
set.seed(91)
waic_m6.7 <- WAIC( m6.7 , pointwise=TRUE )$WAIC
waic_m6.8 <- WAIC( m6.8 , pointwise=TRUE )$WAIC
n <- length(waic_m6.7)
diff_m6.7_m6.8 <- waic_m6.7 - waic_m6.8
sqrt( n*var( diff_m6.7_m6.8 ) )

## R code 7.28
40.0 + c(-1,1)*10.4*2.6

## R code 7.29
plot( compare( m6.6 , m6.7 , m6.8 ) )

## R code 7.30
set.seed(92)
waic_m6.6 <- WAIC( m6.6 , pointwise=TRUE )$WAIC
diff_m6.6_m6.8 <- waic_m6.6 - waic_m6.8
sqrt( n*var( diff_m6.6_m6.8 ) )

## R code 7.31
set.seed(93)
compare( m6.6 , m6.7 , m6.8 )@dSE

## R code 7.32
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
d$A <- standardize( d$MedianAgeMarriage )
d$D <- standardize( d$Divorce )
d$M <- standardize( d$Marriage )

m5.1 <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + bA * A ,
        a ~ dnorm( 0 , 0.2 ) ,
        bA ~ dnorm( 0 , 0.5 ) ,
        sigma ~ dexp( 1 )
    ) , data = d )

m5.2 <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + bM * M ,
        a ~ dnorm( 0 , 0.2 ) ,
        bM ~ dnorm( 0 , 0.5 ) ,
        sigma ~ dexp( 1 )
    ) , data = d )

m5.3 <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + bM*M + bA*A ,
        a ~ dnorm( 0 , 0.2 ) ,
        bM ~ dnorm( 0 , 0.5 ) ,
        bA ~ dnorm( 0 , 0.5 ) ,
        sigma ~ dexp( 1 )
    ) , data = d )

## R code 7.33
set.seed(24071847)
compare( m5.1 , m5.2 , m5.3 , func=PSIS )

## R code 7.34
set.seed(24071847)
PSIS_m5.3 <- PSIS(m5.3,pointwise=TRUE)
set.seed(24071847)
WAIC_m5.3 <- WAIC(m5.3,pointwise=TRUE)
plot( PSIS_m5.3$k , WAIC_m5.3$penalty , xlab="PSIS Pareto k" ,
    ylab="WAIC penalty" , col=rangi2 , lwd=2 )

## R code 7.35
m5.3t <- quap(
    alist(
        D ~ dstudent( 2 , mu , sigma ) ,
        mu <- a + bM*M + bA*A ,
        a ~ dnorm( 0 , 0.2 ) ,
        bM ~ dnorm( 0 , 0.5 ) ,
        bA ~ dnorm( 0 , 0.5 ) ,
        sigma ~ dexp( 1 )
    ) , data = d )


```



When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
